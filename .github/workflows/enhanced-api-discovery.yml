name: Enhanced API Discovery

on:
  schedule:
    # Run weekly on Monday at 00:15 UTC (5:45 AM IST)
    - cron: '15 0 * * 1'
  push:
    branches: [ main ]
  workflow_dispatch:
    # Allow manual triggering

# Set permissions for the GITHUB_TOKEN
permissions:
  contents: write

jobs:
  discover-apis:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 feedparser
          
      - name: Run enhanced API discovery script
        run: python scripts/enhanced_api_scrapers.py
        
      - name: Update README with APIs
        run: python scripts/update_readme_with_apis.py
        
      - name: Check for changes
        id: git-check
        run: |
          git diff --exit-code || echo "changes=true" >> $GITHUB_OUTPUT
          
      - name: Commit and push if changed
        if: steps.git-check.outputs.changes == 'true'
        run: |
          git config --local user.email "gunjanjaswal@gmail.com"
          git config --local user.name "Gunjan Jaswaal"
          git add -A
          git stash
          git pull origin main
          git stash pop || true
          git add -A
          git commit -m "Discover new APIs with enhanced scrapers [skip ci]"
        
      - name: Push changes
        if: steps.git-check.outputs.changes == 'true'
        run: |
          git push --force-with-lease origin HEAD:${{ github.ref }}
